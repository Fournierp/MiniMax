{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniMax TicTacToe\n",
    "\n",
    "In this notebook we will explore the famous MiniMax Algorithm. To do so we will use the simple game of TicTacToe:\n",
    "\n",
    "![alt text](https://upload.wikimedia.org/wikipedia/commons/d/da/TicTacToe-152374698XOp.gif \"Demo GIF\")\n",
    "\n",
    "The rules of that game are simple, align 3 of your pieces horizontally, vertically or diagonaly to win. In this notebook, we will approach the MiniMax algorithm from a naive standpoint by exploring simple algorithms. The first one will be a one step lookahead. Yet let us firstly look at the game environment that is in file \"TicTacToe.py\". The default strategy of the agent is random decision making:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-| -| -| \n",
      "-| -| -| \n",
      "-| -| -| \n",
      "\n",
      "-| -| -| \n",
      "-| -| -| \n",
      "-| X| -| \n",
      "\n",
      "-| -| -| \n",
      "-| -| O| \n",
      "-| X| -| \n",
      "\n",
      "-| -| -| \n",
      "-| -| O| \n",
      "X| X| -| \n",
      "\n",
      "-| -| -| \n",
      "-| -| O| \n",
      "X| X| O| \n",
      "\n",
      "-| -| X| \n",
      "-| -| O| \n",
      "X| X| O| \n",
      "\n",
      "-| O| X| \n",
      "-| -| O| \n",
      "X| X| O| \n",
      "\n",
      "X| O| X| \n",
      "-| -| O| \n",
      "X| X| O| \n",
      "\n",
      "X| O| X| \n",
      "-| O| O| \n",
      "X| X| O| \n",
      "\n",
      "X| O| X| \n",
      "X| O| O| \n",
      "X| X| O| \n",
      "\n",
      "Player 1 won!\n",
      "Player 1: random vs. Player 2: random\n",
      "Player 1 W: 40, L: 46, T: 14 "
     ]
    }
   ],
   "source": [
    "import TicTacToe\n",
    "game = TicTacToe.TicTacToe()\n",
    "game.play()\n",
    "game.percentage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It makes sense that two random agents playing against each other would almost tie. Now let us explore the **One Step Lookahead** algorithm. This algorithm simply looks at the board and finds out if there exist a move that would win the game and plays it accordingly. \n",
    "\n",
    "```python\n",
    "    def agent_next_winning_move(self):\n",
    "        # Agent that plays the next move that wins the board\n",
    "        board_copy = self.game_board.copy()\n",
    "        moves = self.get_valid_moves()\n",
    "        next_move = None\n",
    "        for move in moves:\n",
    "            x, y = int(move / 3), int(move % 3)\n",
    "            board_copy[x][y] = self.player_turn\n",
    "            for i in range(0, 3):\n",
    "                # Vertical winner\n",
    "                if board_copy[0][i] != '-':\n",
    "                    if self.game_board[0][i] == board_copy[1][i] == board_copy[2][i]:\n",
    "                        next_move = move\n",
    "                        break\n",
    "                # Horizontal winner\n",
    "                if board_copy[i][0] != '-':\n",
    "                    if board_copy[i][0] == board_copy[i][1] == board_copy[i][2]:\n",
    "                        next_move = move\n",
    "                        break\n",
    "            # Diagonal winner\n",
    "            if board_copy[1][1] != '-':\n",
    "                if board_copy[0][0] == board_copy[1][1] == board_copy[2][2]:\n",
    "                    next_move = move\n",
    "                    break\n",
    "                elif board_copy[2][0] == board_copy[1][1] == board_copy[0][2]:\n",
    "                    next_move = move\n",
    "                    break\n",
    "            # Tie\n",
    "            for i in range(3):\n",
    "                for j in range(3):\n",
    "                    # If there is at least one tile not filed\n",
    "                    if board_copy[i][j] == '-':\n",
    "                        next_move = None\n",
    "\n",
    "            next_move = None\n",
    "        #\n",
    "        if next_move is not None:\n",
    "            return int(next_move / 3), int(next_move % 3)\n",
    "        else:\n",
    "            xy = random.choice(moves)\n",
    "            return int(xy / 3), int(xy % 3)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| -| -| -| \n",
      "| -| -| -| \n",
      "| -| -| -| \n",
      "\n",
      "| -| -| -| \n",
      "| -| -| -| \n",
      "| X| -| -| \n",
      "\n",
      "| O| -| -| \n",
      "| -| -| -| \n",
      "| X| -| -| \n",
      "\n",
      "| O| -| -| \n",
      "| -| X| -| \n",
      "| X| -| -| \n",
      "\n",
      "| O| -| -| \n",
      "| -| X| -| \n",
      "| X| -| O| \n",
      "\n",
      "| O| -| X| \n",
      "| -| X| -| \n",
      "| X| -| O| \n",
      "\n",
      "Player 1 won!\n",
      "Player 1: next_winning vs. Player 2: random\n",
      "Player 1 W: 64, L: 29, T: 7 "
     ]
    }
   ],
   "source": [
    "from TicTacToe import TicTacToe\n",
    "game = TicTacToe(player1=\"next_winning\", player2=\"random\")\n",
    "game.play()\n",
    "game.percentage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are already promissing.\n",
    "\n",
    "Now the State Space of TicTacToe (the 9 tiles) is quite limited so the One Step Lookahead is quite easy to develop. For more complex games like chess, developping a One Step Lookahead algorithm is more challenging. Indeed our TicTacToe script picks a random position when there is no winning move available. Yet for chess the approach to take would be to build a heuristic function. Even though I have not built one for this project, we can look at the purpose of such a function. As a player, there are position that are more advantageous; the heuristic function simply translates such preferences into a fitness score and the move with the highest score will be selected. In chess we could translate the capture of each piece with a reward which will direct the algorithm to prioritize important pieces over pawns.\n",
    "\n",
    "Given the processing power of computers, why not elaborate the One Step Lookahead to a N Step Lookahead. Instead of simulating a single move and looking at the outcome, we can simulate all possible sets of N moves and observe the outcomes. This method is called the Monte Carlo Simulation.\n",
    "```python\n",
    "    def n_step_rec(self, turn, depth):\n",
    "        # Recursive function that explores different combinations of moves\n",
    "        self.result = self.winner()\n",
    "\n",
    "        # If the Game is over output the outcome\n",
    "        if self.result != None:\n",
    "            if self.result == 'X':\n",
    "                return 1\n",
    "            elif self.result == 'O':\n",
    "                return -1\n",
    "            elif self.result == '-':\n",
    "                return 0\n",
    "        # If the number of exploration reaches a maximum\n",
    "        if depth == 0:\n",
    "            return 0\n",
    "        valid_moves = self.get_valid_moves()\n",
    "        # Simulate a move\n",
    "        if turn == 'X':\n",
    "            value = 0\n",
    "            for move in valid_moves:\n",
    "                x, y = int(move / 3), int(move % 3)\n",
    "                self.game_board[x][y] = turn\n",
    "                value += self.n_step_rec('O', depth - 1)\n",
    "                self.game_board[x][y] = '-'\n",
    "            return value\n",
    "        else:\n",
    "            value = 0\n",
    "            for move in valid_moves:\n",
    "                x, y = int(move / 3), int(move % 3)\n",
    "                self.game_board[x][y] = turn\n",
    "                value += self.n_step_rec('X', depth - 1)\n",
    "                self.game_board[x][y] = '-'\n",
    "\n",
    "            return value\n",
    "```\n",
    "The code is not much harder than previously, it simply extends the search deeper. This is a strategy that humans do subconsciously when playing board games. In chess professionals try to plan several steps ahead to find the optimal move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| -| -| -| \n",
      "| -| -| -| \n",
      "| -| -| -| \n",
      "\n",
      "| -| -| -| \n",
      "| -| X| -| \n",
      "| -| -| -| \n",
      "\n",
      "| -| -| -| \n",
      "| O| X| -| \n",
      "| -| -| -| \n",
      "\n",
      "| X| -| -| \n",
      "| O| X| -| \n",
      "| -| -| -| \n",
      "\n",
      "| X| -| O| \n",
      "| O| X| -| \n",
      "| -| -| -| \n",
      "\n",
      "| X| -| O| \n",
      "| O| X| -| \n",
      "| -| X| -| \n",
      "\n",
      "| X| -| O| \n",
      "| O| X| -| \n",
      "| -| X| O| \n",
      "\n",
      "| X| X| O| \n",
      "| O| X| -| \n",
      "| -| X| O| \n",
      "\n",
      "Player 1 won!\n",
      "Player 1: n_step vs. Player 2: random\n",
      "Player 1 W: 79, L: 5, T: 16 "
     ]
    }
   ],
   "source": [
    "from TicTacToe import TicTacToe\n",
    "game = TicTacToe(player1=\"n_step\", player2=\"random\")\n",
    "game.play()\n",
    "game.percentage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are getting even better yet. The Monte Carlo Tree Search simulates blindly all game states. Yet The ***Minimax*** algorithm will put the assumption that the opponent attempts to play optimally. Indeed, the algorithm will find the move that progressively optimize its winning chances against an agent that attempts to minimize it. The approach taken is to simulate games, record the outcomes and find the path where at each move, we pick the best move for us and the opponent picks the worst one for us.\n",
    "```python\n",
    "    # Minimax implementation\n",
    "    def minimax(self, turn, depth):\n",
    "        # Recursive function that explores different combinations of moves\n",
    "        self.result = self.winner()\n",
    "\n",
    "        # If the Game is over output the outcome\n",
    "        if self.result != None:\n",
    "            if self.result == 'X':\n",
    "                return 1\n",
    "            elif self.result == 'O':\n",
    "                return -1\n",
    "            elif self.result == '-':\n",
    "                return 0\n",
    "        # If the number of exploration reaches a maximum\n",
    "        if depth == 0:\n",
    "            return 0\n",
    "\n",
    "        valid_moves = self.get_valid_moves()\n",
    "        if turn == 'X':\n",
    "            value = -np.Inf\n",
    "            for move in valid_moves:\n",
    "                x, y = int(move / 3), int(move % 3)\n",
    "                self.game_board[x][y] = turn\n",
    "                value = max(value, self.n_step_rec('O', depth - 1))\n",
    "                self.game_board[x][y] = '-'\n",
    "            return value\n",
    "        else:\n",
    "            value = np.Inf\n",
    "            for move in valid_moves:\n",
    "                x, y = int(move / 3), int(move % 3)\n",
    "                self.game_board[x][y] = turn\n",
    "                value = min(value, self.n_step_rec('X', depth - 1))\n",
    "                self.game_board[x][y] = '-'\n",
    "\n",
    "            return value\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| -| -| -| \n",
      "| -| -| -| \n",
      "| -| -| -| \n",
      "\n",
      "| -| X| -| \n",
      "| -| -| -| \n",
      "| -| -| -| \n",
      "\n",
      "| -| X| O| \n",
      "| -| -| -| \n",
      "| -| -| -| \n",
      "\n",
      "| -| X| O| \n",
      "| -| X| -| \n",
      "| -| -| -| \n",
      "\n",
      "| -| X| O| \n",
      "| O| X| -| \n",
      "| -| -| -| \n",
      "\n",
      "| -| X| O| \n",
      "| O| X| -| \n",
      "| -| X| -| \n",
      "\n",
      "Player 1 won!\n",
      "Player 1: minimax vs. Player 2: random\n",
      "Player 1 W: 78, L: 8, T: 14 "
     ]
    }
   ],
   "source": [
    "from TicTacToe import TicTacToe\n",
    "game = TicTacToe(player1=\"minimax\", player2=\"random\")\n",
    "game.play()\n",
    "game.percentage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are quite similar to those from the Monte Carlo Search Tree. TicTacToe is a ---. And Monte CArlo Simulations converge to the Minimax solution for such games. A final improvement we can provide for the Minimax algorithm is ***Alpha Beta Pruning***. The process of simulating games can be quite time consumming especially for large game trees. A way we can improve the efficiency is to ignore suboptimal moves when a better move is found. To be more precise, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
